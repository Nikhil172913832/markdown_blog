Bayesian Optimization is a **global optimization technique** that finds the best hyperparameters **by modeling the objective function probabilistically** instead of blindly searching. The math involves two key components:

1. **Surrogate Function (Gaussian Process - GP)**
    
2. **Acquisition Function (Expected Improvement, Upper Confidence Bound, etc.)**
    

---

## **1. Surrogate Function: Gaussian Process (GP) Regression**

Since evaluating hyperparameters is expensive (e.g., training deep networks takes hours), we approximate the objective function f(x)f(x)f(x) using a surrogate function.

A **Gaussian Process (GP)** is a **non-parametric** model that estimates f(x)f(x)f(x) with **a mean and uncertainty (variance) at every point**.

### **Gaussian Process Definition**

A GP defines a **distribution over functions**:

f(x)âˆ¼GP(m(x),k(x,xâ€²))f(x) \sim \mathcal{GP}(m(x), k(x, x'))f(x)âˆ¼GP(m(x),k(x,xâ€²))

Where:

- m(x)m(x)m(x) is the **mean function** (usually assumed to be 0).
    
- k(x,xâ€²)k(x, x')k(x,xâ€²) is the **covariance/kernel function**, which measures similarity between points xxx and xâ€²x'xâ€².
    

---

### **Gaussian Process Prior & Posterior**

Initially, before evaluating any points, we assume:

f(x)âˆ¼N(0,K)f(x) \sim \mathcal{N}(0, K)f(x)âˆ¼N(0,K)

where KKK is the covariance matrix using a kernel function like **Radial Basis Function (RBF)**:

k(x,xâ€²)=expâ¡(âˆ’âˆ£âˆ£xâˆ’xâ€²âˆ£âˆ£22l2)k(x, x') = \exp\left(-\frac{||x - x'||^2}{2l^2}\right)k(x,xâ€²)=exp(âˆ’2l2âˆ£âˆ£xâˆ’xâ€²âˆ£âˆ£2â€‹)

After observing some data points (X,y)(X, y)(X,y), we **update our belief** about f(x)f(x)f(x) using **Bayes' Theorem**:

p(f(x)âˆ£X,y)âˆ¼N(Î¼(x),Ïƒ2(x))p(f(x) | X, y) \sim \mathcal{N}(\mu(x), \sigma^2(x))p(f(x)âˆ£X,y)âˆ¼N(Î¼(x),Ïƒ2(x))

where:

- **Mean Î¼(x)\mu(x)Î¼(x)**: Our best estimate of f(x)f(x)f(x).
    
- **Variance Ïƒ2(x)\sigma^2(x)Ïƒ2(x)**: Our uncertainty at each point.
    

The mean and variance of the Gaussian Process posterior are computed as:

Î¼(x)=KxXKXXâˆ’1y\mu(x) = K_{xX} K_{XX}^{-1} yÎ¼(x)=KxXâ€‹KXXâˆ’1â€‹y Ïƒ2(x)=Kxxâˆ’KxXKXXâˆ’1KXx\sigma^2(x) = K_{xx} - K_{xX} K_{XX}^{-1} K_{Xx}Ïƒ2(x)=Kxxâ€‹âˆ’KxXâ€‹KXXâˆ’1â€‹KXxâ€‹

where:

- KXXK_{XX}KXXâ€‹ is the covariance matrix of observed data.
    
- KxXK_{xX}KxXâ€‹ is the covariance between new and observed points.
    
- KxxK_{xx}Kxxâ€‹ is the self-covariance of new points.
    

This allows us to **predict the function without explicitly defining it!** ðŸš€

---

## **2. Acquisition Function: Selecting the Next Point**

Now that we have a Gaussian Process model for f(x)f(x)f(x), we need to decide **where to sample next**. This is done using an **acquisition function** that balances **exploration vs exploitation**.

### **Common Acquisition Functions**

1. **Expected Improvement (EI)**
    
    - Picks points that **maximize expected improvement** over the current best result.
        
    - Formula:
        
        EI(x)=E[maxâ¡(0,f(x)âˆ’fâˆ—)]EI(x) = \mathbb{E}[\max(0, f(x) - f^*)]EI(x)=E[max(0,f(x)âˆ’fâˆ—)]
        
        where fâˆ—f^*fâˆ— is the best observed function value so far.
        
    - This encourages selecting points with high predicted values and high uncertainty.
        
2. **Upper Confidence Bound (UCB)**
    
    - Selects points that maximize:
        
        UCB(x)=Î¼(x)+ÎºÏƒ(x)UCB(x) = \mu(x) + \kappa \sigma(x)UCB(x)=Î¼(x)+ÎºÏƒ(x)
    - **Îº\kappaÎº controls exploration-exploitation** trade-off.
        
        - **Large Îº\kappaÎº** â†’ More exploration.
            
        - **Small Îº\kappaÎº** â†’ More exploitation.
            
3. **Probability of Improvement (PI)**
    
    - Picks points where probability of improvement is highest:
        
        PI(x)=P(f(x)>fâˆ—)PI(x) = P(f(x) > f^*)PI(x)=P(f(x)>fâˆ—)
    - This strategy is simple but less effective than EI.
        

---

## **3. Full Bayesian Optimization Algorithm**

Now we put everything together:

1. **Initialize** with a few randomly selected hyperparameters.
    
2. **Fit a Gaussian Process** to model the objective function f(x)f(x)f(x).
    
3. **Use an acquisition function** (EI, UCB, PI) to choose the next best hyperparameter.
    
4. **Evaluate the objective function** at the chosen hyperparameter.
    
5. **Update the Gaussian Process model** with the new observation.
    
6. **Repeat until convergence** (or budget runs out).
    

---

## **4. Why Bayesian Optimization is Efficient**

âœ… **Learns from past evaluations** â†’ Doesn't waste time on bad regions.  
âœ… **Uncertainty-aware** â†’ Balances exploration and exploitation.  
âœ… **Works well with expensive function evaluations** (Deep Learning, Hyperparameter tuning).

ðŸ”´ **Downside?**

- **Computational cost** increases as the number of evaluations grows (because GP inversion scales as O(n3)O(n^3)O(n3)).
    
- **Not ideal for very high-dimensional spaces**, but TPE (Tree-structured Parzen Estimators) solve this.